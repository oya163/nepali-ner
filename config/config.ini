[DATA]
data_file = ./data/ebiquity_v2/total.bio
root_path = ./data/ebiquity_v2/kfold
#data_file = ./data/ebiquity/stemmed/total.bio
#root_path = ./data/ebiquity/stemmed/kfold
#data_file = ./data/eng/total.bio
#root_path = ./data/eng/kfold
shuffle = True

[EMBEDDINGS]
pretrained = True
emb_dir = ./embeddings/fasttext
emb_file = nep2ft.vec
#emb_dir = ./embeddings/fasttext/eng
#emb_file = wiki-news-300d-1M.vec
embedding_dim = 300
embed_finetune = True
char_pretrained = False
char_emb_file = char_vectors_30.txt
graph_emb_file = graph_vectors_30.txt
char_dim = 30

[OUTPUT_DIR]
output_dir = ./saved_models
results_dir = ./results

[TRAIN]
batch_size = 8
epochs = 100
early_max_patience = 5
log_interval = 100

[OPTIM]
learning_rate = 0.05
weight_decay = 0.000001
momentum = 0.0
clip_max_norm_use = False
clip_max_norm = None
use_lr_decay = True
lr_rate_decay = noam_step
learning_rate_warmup_steps = 100
min_lrate = 0.000005
max_patience = 2

[MODEL]
model_name = lstm_
bidirection = True
num_layers = 1
hidden_dim = 100
dropout_embed = 0.0
dropout = 0.5

[EVALUATION]
raw = True
delimiter
oTag = 'O'
latex = False